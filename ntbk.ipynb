{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from utils import *\n",
    "from models import *\n",
    "from attention import *\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== THE DATASET IS READY ========\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "get_file()\n",
    "path_to_file = 'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of line in the dataset is 118964\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000 #118960\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27000 27000 3000 3000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "29 ----> le\n",
      "218 ----> dio\n",
      "15 ----> un\n",
      "4709 ----> derrame\n",
      "4413 ----> cerebral\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "14 ----> he\n",
      "98 ----> had\n",
      "9 ----> a\n",
      "1801 ----> stroke\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "tensor_x = torch.Tensor(input_tensor_train).long() \n",
    "tensor_y = torch.Tensor(target_tensor_train).long()\n",
    "# create your datset\n",
    "my_dataset = data.TensorDataset(tensor_x,tensor_y) \n",
    "# create your dataloader\n",
    "my_dataloader = data.DataLoader(my_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(my_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) torch.Size([64, 16, 1024])\n",
      "Encoder Hidden state shape: (batch size, units) torch.Size([1, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) torch.Size([64, 1024])\n",
      "Attention weights shape: (batch_size, sequence_length, 1) torch.Size([64, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10, 1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) torch.Size([64, 4935])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(torch.randint(1, 20, (BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE).to(device)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 7.7412\n",
      "Epoch 1 Batch 100 Loss 2.9554\n",
      "Epoch 1 Batch 200 Loss 1.7669\n",
      "Epoch 1 Batch 300 Loss 1.7452\n",
      "Epoch 1 Batch 400 Loss 1.5936\n",
      "Epoch 1 Loss 2.3889\n",
      "Time taken for 1 epoch 51.04140591621399 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.8061\n",
      "Epoch 2 Batch 100 Loss 1.6770\n",
      "Epoch 2 Batch 200 Loss 1.2777\n",
      "Epoch 2 Batch 300 Loss 1.4972\n",
      "Epoch 2 Batch 400 Loss 1.3039\n",
      "Epoch 2 Loss 1.4296\n",
      "Time taken for 1 epoch 58.86311888694763 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1222\n",
      "Epoch 3 Batch 100 Loss 0.7756\n",
      "Epoch 3 Batch 200 Loss 1.0107\n",
      "Epoch 3 Batch 300 Loss 1.1219\n",
      "Epoch 3 Batch 400 Loss 0.7562\n",
      "Epoch 3 Loss 0.9706\n",
      "Time taken for 1 epoch 45.40136790275574 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.5320\n",
      "Epoch 4 Batch 100 Loss 0.8455\n",
      "Epoch 4 Batch 200 Loss 0.5010\n",
      "Epoch 4 Batch 300 Loss 0.8171\n",
      "Epoch 4 Batch 400 Loss 0.4678\n",
      "Epoch 4 Loss 0.6913\n",
      "Time taken for 1 epoch 45.684128284454346 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.7115\n",
      "Epoch 5 Batch 100 Loss 0.2202\n",
      "Epoch 5 Batch 200 Loss 0.5974\n",
      "Epoch 5 Batch 300 Loss 0.3932\n",
      "Epoch 5 Batch 400 Loss 0.5639\n",
      "Epoch 5 Loss 0.5052\n",
      "Time taken for 1 epoch 45.408111810684204 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4928\n",
      "Epoch 6 Batch 100 Loss 0.5930\n",
      "Epoch 6 Batch 200 Loss 0.2718\n",
      "Epoch 6 Batch 300 Loss 0.2586\n",
      "Epoch 6 Batch 400 Loss 0.2209\n",
      "Epoch 6 Loss 0.4033\n",
      "Time taken for 1 epoch 45.43382406234741 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.3656\n",
      "Epoch 7 Batch 100 Loss 0.1653\n",
      "Epoch 7 Batch 200 Loss 0.1700\n",
      "Epoch 7 Batch 300 Loss 0.1864\n",
      "Epoch 7 Batch 400 Loss 0.1894\n",
      "Epoch 7 Loss 0.3191\n",
      "Time taken for 1 epoch 45.48565602302551 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1242\n",
      "Epoch 8 Batch 100 Loss 0.3233\n",
      "Epoch 8 Batch 200 Loss 0.2841\n",
      "Epoch 8 Batch 300 Loss 0.2882\n",
      "Epoch 8 Batch 400 Loss 0.1996\n",
      "Epoch 8 Loss 0.2582\n",
      "Time taken for 1 epoch 45.50555372238159 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.2977\n",
      "Epoch 9 Batch 100 Loss 0.1149\n",
      "Epoch 9 Batch 200 Loss 0.3630\n",
      "Epoch 9 Batch 300 Loss 0.1476\n",
      "Epoch 9 Batch 400 Loss 0.3541\n",
      "Epoch 9 Loss 0.2142\n",
      "Time taken for 1 epoch 42.81729555130005 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2323\n",
      "Epoch 10 Batch 100 Loss 0.2330\n",
      "Epoch 10 Batch 200 Loss 0.2236\n",
      "Epoch 10 Batch 300 Loss 0.1014\n",
      "Epoch 10 Batch 400 Loss 0.0976\n",
      "Epoch 10 Loss 0.1810\n",
      "Time taken for 1 epoch 42.33812975883484 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0724\n",
      "Epoch 11 Batch 100 Loss 0.3054\n",
      "Epoch 11 Batch 200 Loss 0.2770\n",
      "Epoch 11 Batch 300 Loss 0.1393\n",
      "Epoch 11 Batch 400 Loss 0.2974\n",
      "Epoch 11 Loss 0.1802\n",
      "Time taken for 1 epoch 43.12398600578308 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1497\n",
      "Epoch 12 Batch 100 Loss 0.2247\n",
      "Epoch 12 Batch 200 Loss 0.0603\n",
      "Epoch 12 Batch 300 Loss 0.1009\n",
      "Epoch 12 Batch 400 Loss 0.2939\n",
      "Epoch 12 Loss 0.1648\n",
      "Time taken for 1 epoch 44.25855731964111 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.2216\n",
      "Epoch 13 Batch 100 Loss 0.0706\n",
      "Epoch 13 Batch 200 Loss 0.0941\n",
      "Epoch 13 Batch 300 Loss 0.3477\n",
      "Epoch 13 Batch 400 Loss 0.3266\n",
      "Epoch 13 Loss 0.1605\n",
      "Time taken for 1 epoch 47.44200944900513 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1598\n",
      "Epoch 14 Batch 100 Loss 0.0562\n",
      "Epoch 14 Batch 200 Loss 0.2247\n",
      "Epoch 14 Batch 300 Loss 0.2192\n",
      "Epoch 14 Batch 400 Loss 0.1159\n",
      "Epoch 14 Loss 0.1456\n",
      "Time taken for 1 epoch 46.9210102558136 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1499\n",
      "Epoch 15 Batch 100 Loss 0.3041\n",
      "Epoch 15 Batch 200 Loss 0.2254\n",
      "Epoch 15 Batch 300 Loss 0.2329\n",
      "Epoch 15 Batch 400 Loss 0.0664\n",
      "Epoch 15 Loss 0.1423\n",
      "Time taken for 1 epoch 46.15059041976929 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0615\n",
      "Epoch 16 Batch 100 Loss 0.1800\n",
      "Epoch 16 Batch 200 Loss 0.1727\n",
      "Epoch 16 Batch 300 Loss 0.0609\n",
      "Epoch 16 Batch 400 Loss 0.0774\n",
      "Epoch 16 Loss 0.1408\n",
      "Time taken for 1 epoch 45.945807456970215 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.2007\n",
      "Epoch 17 Batch 100 Loss 0.1062\n",
      "Epoch 17 Batch 200 Loss 0.0627\n",
      "Epoch 17 Batch 300 Loss 0.0978\n",
      "Epoch 17 Batch 400 Loss 0.1898\n",
      "Epoch 17 Loss 0.1217\n",
      "Time taken for 1 epoch 46.00458884239197 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0482\n",
      "Epoch 18 Batch 100 Loss 0.0655\n",
      "Epoch 18 Batch 200 Loss 0.0599\n",
      "Epoch 18 Batch 300 Loss 0.2078\n",
      "Epoch 18 Batch 400 Loss 0.0764\n",
      "Epoch 18 Loss 0.1061\n",
      "Time taken for 1 epoch 47.10262060165405 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1051\n",
      "Epoch 19 Batch 100 Loss 0.0706\n",
      "Epoch 19 Batch 200 Loss 0.0598\n",
      "Epoch 19 Batch 300 Loss 0.1013\n",
      "Epoch 19 Batch 400 Loss 0.0886\n",
      "Epoch 19 Loss 0.1231\n",
      "Time taken for 1 epoch 45.920960664749146 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0596\n",
      "Epoch 20 Batch 100 Loss 0.0890\n",
      "Epoch 20 Batch 200 Loss 0.3152\n",
      "Epoch 20 Batch 300 Loss 0.0722\n",
      "Epoch 20 Batch 400 Loss 0.0488\n",
      "Epoch 20 Loss 0.1192\n",
      "Time taken for 1 epoch 45.90570878982544 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(my_dataloader):\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        batch_loss = train_step(inp, targ, encoder, decoder,\n",
    "                                encoder_optimizer, decoder_optimizer,\n",
    "                                criterion, device, BATCH_SIZE, targ_lang)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to figure it out . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: are you still at home ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'¿ todavia estan en casa ?', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'esta es mi vida .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s very cold here . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
