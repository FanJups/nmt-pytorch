{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from utils import *\n",
    "from models import *\n",
    "from attention import *\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== THE DATASET IS READY ========\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "get_file()\n",
    "path_to_file = 'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4280 ----> sirvanse\n",
      "154 ----> otra\n",
      "2531 ----> copa\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "29 ----> have\n",
      "372 ----> another\n",
      "748 ----> cup\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1, 4280,  154, ...,    0,    0,    0],\n",
       "       [   1,    9,   17, ...,    0,    0,    0],\n",
       "       [   1,    6,   52, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1, 3832,   31, ...,    0,    0,    0],\n",
       "       [   1,   38,  642, ...,    0,    0,    0],\n",
       "       [   1,    7,   61, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "tensor_x = torch.Tensor(input_tensor_train).long() \n",
    "tensor_y = torch.Tensor(target_tensor_train).long()\n",
    "# create your datset\n",
    "my_dataset = data.TensorDataset(tensor_x,tensor_y) \n",
    "# create your dataloader\n",
    "my_dataloader = data.DataLoader(my_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1, 501,  10,   4,   3,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0]),\n",
       " tensor([ 1, 28, 43,  5,  3,  2,  0,  0,  0,  0,  0]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(my_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) torch.Size([64, 16, 1024])\n",
      "Encoder Hidden state shape: (batch size, units) torch.Size([1, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) torch.Size([64, 1024])\n",
      "Attention weights shape: (batch_size, sequence_length, 1) torch.Size([64, 16, 1])\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10, 1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) torch.Size([64, 4935])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(torch.randint(1, 20, (BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE).to(device)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 7.7095\n",
      "Epoch 1 Batch 100 Loss 1.7956\n",
      "Epoch 1 Batch 200 Loss 1.4834\n",
      "Epoch 1 Batch 300 Loss 1.1799\n",
      "Epoch 1 Loss 1.5976\n",
      "Time taken for 1 epoch 40.82125377655029 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.7981\n",
      "Epoch 2 Batch 100 Loss 0.7514\n",
      "Epoch 2 Batch 200 Loss 0.7692\n",
      "Epoch 2 Batch 300 Loss 0.7020\n",
      "Epoch 2 Loss 0.7684\n",
      "Time taken for 1 epoch 37.96637535095215 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.3821\n",
      "Epoch 3 Batch 100 Loss 0.3398\n",
      "Epoch 3 Batch 200 Loss 0.3608\n",
      "Epoch 3 Batch 300 Loss 0.4561\n",
      "Epoch 3 Loss 0.4173\n",
      "Time taken for 1 epoch 37.8361234664917 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2914\n",
      "Epoch 4 Batch 100 Loss 0.2483\n",
      "Epoch 4 Batch 200 Loss 0.2497\n",
      "Epoch 4 Batch 300 Loss 0.2356\n",
      "Epoch 4 Loss 0.2374\n",
      "Time taken for 1 epoch 39.842841148376465 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1293\n",
      "Epoch 5 Batch 100 Loss 0.1336\n",
      "Epoch 5 Batch 200 Loss 0.1632\n",
      "Epoch 5 Batch 300 Loss 0.1716\n",
      "Epoch 5 Loss 0.1502\n",
      "Time taken for 1 epoch 37.5951452255249 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0819\n",
      "Epoch 6 Batch 100 Loss 0.0986\n",
      "Epoch 6 Batch 200 Loss 0.0746\n",
      "Epoch 6 Batch 300 Loss 0.1368\n",
      "Epoch 6 Loss 0.1096\n",
      "Time taken for 1 epoch 37.80324673652649 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0927\n",
      "Epoch 7 Batch 100 Loss 0.0835\n",
      "Epoch 7 Batch 200 Loss 0.0781\n",
      "Epoch 7 Batch 300 Loss 0.0808\n",
      "Epoch 7 Loss 0.0876\n",
      "Time taken for 1 epoch 37.57512831687927 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0490\n",
      "Epoch 8 Batch 100 Loss 0.0542\n",
      "Epoch 8 Batch 200 Loss 0.0440\n",
      "Epoch 8 Batch 300 Loss 0.0762\n",
      "Epoch 8 Loss 0.0757\n",
      "Time taken for 1 epoch 37.593918323516846 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0630\n",
      "Epoch 9 Batch 100 Loss 0.0630\n",
      "Epoch 9 Batch 200 Loss 0.0799\n",
      "Epoch 9 Batch 300 Loss 0.0780\n",
      "Epoch 9 Loss 0.0702\n",
      "Time taken for 1 epoch 37.664902210235596 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0475\n",
      "Epoch 10 Batch 100 Loss 0.0892\n",
      "Epoch 10 Batch 200 Loss 0.0873\n",
      "Epoch 10 Batch 300 Loss 0.0984\n",
      "Epoch 10 Loss 0.0670\n",
      "Time taken for 1 epoch 37.66086173057556 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    #enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(my_dataloader):\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        batch_loss = train_step(inp, targ, encoder, decoder,\n",
    "                                encoder_optimizer, decoder_optimizer,\n",
    "                                criterion, device, BATCH_SIZE, targ_lang)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
