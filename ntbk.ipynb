{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from utils import *\n",
    "from models import *\n",
    "from attention import *\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== THE DATASET IS READY ========\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "get_file()\n",
    "path_to_file = 'spa-eng/spa.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of line in the dataset is 118964\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 118960\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107064 107064 11896 11896\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "6 ----> el\n",
      "985 ----> caballo\n",
      "1568 ----> salto\n",
      "10 ----> la\n",
      "273 ----> cerca\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> the\n",
      "897 ----> horse\n",
      "1462 ----> jumped\n",
      "182 ----> over\n",
      "5 ----> the\n",
      "1097 ----> fence\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)// BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to torch tensor\n",
    "tensor_x = torch.Tensor(input_tensor_train).long() \n",
    "tensor_y = torch.Tensor(target_tensor_train).long()\n",
    "# create your datset\n",
    "my_dataset = data.TensorDataset(tensor_x,tensor_y) \n",
    "# create your dataloader\n",
    "my_dataloader = data.DataLoader(my_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input_batch, example_target_batch = next(iter(my_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 42])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) torch.Size([64, 42, 1024])\n",
      "Encoder Hidden state shape: (batch size, units) torch.Size([1, 64, 1024])\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) torch.Size([64, 1024])\n",
      "Attention weights shape: (batch_size, sequence_length, 1) torch.Size([64, 42, 1])\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10, 1024)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) torch.Size([64, 12928])\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(torch.randint(1, 20, (BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE).to(device)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE, 1024).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 9.2608\n",
      "Epoch 1 Batch 100 Loss 1.2064\n",
      "Epoch 1 Batch 200 Loss 1.0059\n",
      "Epoch 1 Batch 300 Loss 0.9665\n",
      "Epoch 1 Batch 400 Loss 0.8580\n",
      "Epoch 1 Batch 500 Loss 1.1753\n",
      "Epoch 1 Batch 600 Loss 0.6670\n",
      "Epoch 1 Batch 700 Loss 1.2707\n",
      "Epoch 1 Batch 800 Loss 0.8587\n",
      "Epoch 1 Batch 900 Loss 0.8064\n",
      "Epoch 1 Batch 1000 Loss 0.5194\n",
      "Epoch 1 Batch 1100 Loss 0.6535\n",
      "Epoch 1 Batch 1200 Loss 0.5530\n",
      "Epoch 1 Batch 1300 Loss 0.7081\n",
      "Epoch 1 Batch 1400 Loss 0.4992\n",
      "Epoch 1 Batch 1500 Loss 0.7700\n",
      "Epoch 1 Batch 1600 Loss 0.5741\n",
      "Epoch 1 Loss 0.9015\n",
      "Time taken for 1 epoch 1096.3403565883636 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.7643\n",
      "Epoch 2 Batch 100 Loss 0.3729\n",
      "Epoch 2 Batch 200 Loss 0.6865\n",
      "Epoch 2 Batch 300 Loss 0.4449\n",
      "Epoch 2 Batch 400 Loss 0.6956\n",
      "Epoch 2 Batch 500 Loss 0.6835\n",
      "Epoch 2 Batch 600 Loss 0.3482\n",
      "Epoch 2 Batch 700 Loss 0.6420\n",
      "Epoch 2 Batch 800 Loss 0.5980\n",
      "Epoch 2 Batch 900 Loss 0.6265\n",
      "Epoch 2 Batch 1000 Loss 0.4531\n",
      "Epoch 2 Batch 1100 Loss 0.3546\n",
      "Epoch 2 Batch 1200 Loss 0.6791\n",
      "Epoch 2 Batch 1300 Loss 0.3768\n",
      "Epoch 2 Batch 1400 Loss 0.4132\n",
      "Epoch 2 Batch 1500 Loss 0.5765\n",
      "Epoch 2 Batch 1600 Loss 0.5570\n",
      "Epoch 2 Loss 0.5296\n",
      "Time taken for 1 epoch 1123.746752500534 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.2973\n",
      "Epoch 3 Batch 100 Loss 0.2447\n",
      "Epoch 3 Batch 200 Loss 0.2896\n",
      "Epoch 3 Batch 300 Loss 0.3035\n",
      "Epoch 3 Batch 400 Loss 0.4786\n",
      "Epoch 3 Batch 500 Loss 0.5714\n",
      "Epoch 3 Batch 600 Loss 0.5335\n",
      "Epoch 3 Batch 700 Loss 0.6174\n",
      "Epoch 3 Batch 800 Loss 0.2688\n",
      "Epoch 3 Batch 900 Loss 0.3068\n",
      "Epoch 3 Batch 1000 Loss 0.4679\n",
      "Epoch 3 Batch 1100 Loss 0.5114\n",
      "Epoch 3 Batch 1200 Loss 0.4567\n",
      "Epoch 3 Batch 1300 Loss 0.3380\n",
      "Epoch 3 Batch 1400 Loss 0.4802\n",
      "Epoch 3 Batch 1500 Loss 0.4557\n",
      "Epoch 3 Batch 1600 Loss 0.5939\n",
      "Epoch 3 Loss 0.4027\n",
      "Time taken for 1 epoch 1095.315892457962 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2839\n",
      "Epoch 4 Batch 100 Loss 0.2244\n",
      "Epoch 4 Batch 200 Loss 0.3660\n",
      "Epoch 4 Batch 300 Loss 0.2468\n",
      "Epoch 4 Batch 400 Loss 0.2619\n",
      "Epoch 4 Batch 500 Loss 0.3504\n",
      "Epoch 4 Batch 600 Loss 0.3966\n",
      "Epoch 4 Batch 700 Loss 0.5894\n",
      "Epoch 4 Batch 800 Loss 0.3141\n",
      "Epoch 4 Batch 900 Loss 0.2484\n",
      "Epoch 4 Batch 1000 Loss 0.2318\n",
      "Epoch 4 Batch 1100 Loss 0.2378\n",
      "Epoch 4 Batch 1200 Loss 0.2622\n",
      "Epoch 4 Batch 1300 Loss 0.2499\n",
      "Epoch 4 Batch 1400 Loss 0.3810\n",
      "Epoch 4 Batch 1500 Loss 0.5445\n",
      "Epoch 4 Batch 1600 Loss 0.2400\n",
      "Epoch 4 Loss 0.3325\n",
      "Time taken for 1 epoch 1095.273416519165 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.3351\n",
      "Epoch 5 Batch 100 Loss 0.4081\n",
      "Epoch 5 Batch 200 Loss 0.3361\n",
      "Epoch 5 Batch 300 Loss 0.1916\n",
      "Epoch 5 Batch 400 Loss 0.2043\n",
      "Epoch 5 Batch 500 Loss 0.3999\n",
      "Epoch 5 Batch 600 Loss 0.1754\n",
      "Epoch 5 Batch 700 Loss 0.2173\n",
      "Epoch 5 Batch 800 Loss 0.1720\n",
      "Epoch 5 Batch 900 Loss 0.2294\n",
      "Epoch 5 Batch 1000 Loss 0.2074\n",
      "Epoch 5 Batch 1100 Loss 0.4038\n",
      "Epoch 5 Batch 1200 Loss 0.3612\n",
      "Epoch 5 Batch 1300 Loss 0.4644\n",
      "Epoch 5 Batch 1400 Loss 0.4017\n",
      "Epoch 5 Batch 1500 Loss 0.3307\n",
      "Epoch 5 Batch 1600 Loss 0.2307\n",
      "Epoch 5 Loss 0.2848\n",
      "Time taken for 1 epoch 1095.0934159755707 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2702\n",
      "Epoch 6 Batch 100 Loss 0.3225\n",
      "Epoch 6 Batch 200 Loss 0.1590\n",
      "Epoch 6 Batch 300 Loss 0.1530\n",
      "Epoch 6 Batch 400 Loss 0.3495\n",
      "Epoch 6 Batch 500 Loss 0.3474\n",
      "Epoch 6 Batch 600 Loss 0.3344\n",
      "Epoch 6 Batch 700 Loss 0.1061\n",
      "Epoch 6 Batch 800 Loss 0.2713\n",
      "Epoch 6 Batch 900 Loss 0.1702\n",
      "Epoch 6 Batch 1000 Loss 0.1902\n",
      "Epoch 6 Batch 1100 Loss 0.3539\n",
      "Epoch 6 Batch 1200 Loss 0.1253\n",
      "Epoch 6 Batch 1300 Loss 0.2021\n",
      "Epoch 6 Batch 1400 Loss 0.1812\n",
      "Epoch 6 Batch 1500 Loss 0.3100\n",
      "Epoch 6 Batch 1600 Loss 0.3591\n",
      "Epoch 6 Loss 0.2476\n",
      "Time taken for 1 epoch 1094.8093612194061 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.2983\n",
      "Epoch 7 Batch 100 Loss 0.2778\n",
      "Epoch 7 Batch 200 Loss 0.2956\n",
      "Epoch 7 Batch 300 Loss 0.1292\n",
      "Epoch 7 Batch 400 Loss 0.1276\n",
      "Epoch 7 Batch 500 Loss 0.1715\n",
      "Epoch 7 Batch 600 Loss 0.1365\n",
      "Epoch 7 Batch 700 Loss 0.1538\n",
      "Epoch 7 Batch 800 Loss 0.1875\n",
      "Epoch 7 Batch 900 Loss 0.1226\n",
      "Epoch 7 Batch 1000 Loss 0.1368\n",
      "Epoch 7 Batch 1100 Loss 0.3118\n",
      "Epoch 7 Batch 1200 Loss 0.3062\n",
      "Epoch 7 Batch 1300 Loss 0.3645\n",
      "Epoch 7 Batch 1400 Loss 0.3589\n",
      "Epoch 7 Batch 1500 Loss 0.3310\n",
      "Epoch 7 Batch 1600 Loss 0.2614\n",
      "Epoch 7 Loss 0.2198\n",
      "Time taken for 1 epoch 1095.1883943080902 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2440\n",
      "Epoch 8 Batch 100 Loss 0.1092\n",
      "Epoch 8 Batch 200 Loss 0.2369\n",
      "Epoch 8 Batch 300 Loss 0.2001\n",
      "Epoch 8 Batch 400 Loss 0.2120\n",
      "Epoch 8 Batch 500 Loss 0.1955\n",
      "Epoch 8 Batch 600 Loss 0.2356\n",
      "Epoch 8 Batch 700 Loss 0.3442\n",
      "Epoch 8 Batch 800 Loss 0.1285\n",
      "Epoch 8 Batch 900 Loss 0.3065\n",
      "Epoch 8 Batch 1000 Loss 0.1086\n",
      "Epoch 8 Batch 1100 Loss 0.1427\n",
      "Epoch 8 Batch 1200 Loss 0.1406\n",
      "Epoch 8 Batch 1300 Loss 0.1294\n",
      "Epoch 8 Batch 1400 Loss 0.1308\n",
      "Epoch 8 Batch 1500 Loss 0.3487\n",
      "Epoch 8 Batch 1600 Loss 0.2628\n",
      "Epoch 8 Loss 0.1993\n",
      "Time taken for 1 epoch 1094.3911719322205 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1613\n",
      "Epoch 9 Batch 100 Loss 0.1138\n",
      "Epoch 9 Batch 200 Loss 0.1032\n",
      "Epoch 9 Batch 300 Loss 0.1366\n",
      "Epoch 9 Batch 400 Loss 0.1150\n",
      "Epoch 9 Batch 500 Loss 0.1332\n",
      "Epoch 9 Batch 600 Loss 0.2224\n",
      "Epoch 9 Batch 700 Loss 0.2755\n",
      "Epoch 9 Batch 800 Loss 0.2125\n",
      "Epoch 9 Batch 900 Loss 0.1034\n",
      "Epoch 9 Batch 1000 Loss 0.2909\n",
      "Epoch 9 Batch 1100 Loss 0.1098\n",
      "Epoch 9 Batch 1200 Loss 0.3432\n",
      "Epoch 9 Batch 1300 Loss 0.2848\n",
      "Epoch 9 Batch 1400 Loss 0.1483\n",
      "Epoch 9 Batch 1500 Loss 0.1402\n",
      "Epoch 9 Batch 1600 Loss 0.2471\n",
      "Epoch 9 Loss 0.1964\n",
      "Time taken for 1 epoch 1094.5523817539215 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2394\n",
      "Epoch 10 Batch 100 Loss 0.2158\n",
      "Epoch 10 Batch 200 Loss 0.2330\n",
      "Epoch 10 Batch 300 Loss 0.1162\n",
      "Epoch 10 Batch 400 Loss 0.0838\n",
      "Epoch 10 Batch 500 Loss 0.1408\n",
      "Epoch 10 Batch 600 Loss 0.0966\n",
      "Epoch 10 Batch 700 Loss 0.1079\n",
      "Epoch 10 Batch 800 Loss 0.0920\n",
      "Epoch 10 Batch 900 Loss 0.2674\n",
      "Epoch 10 Batch 1000 Loss 0.2132\n",
      "Epoch 10 Batch 1100 Loss 0.1156\n",
      "Epoch 10 Batch 1200 Loss 0.1316\n",
      "Epoch 10 Batch 1300 Loss 0.0965\n",
      "Epoch 10 Batch 1400 Loss 0.1102\n",
      "Epoch 10 Batch 1500 Loss 0.2752\n",
      "Epoch 10 Batch 1600 Loss 0.1730\n",
      "Epoch 10 Loss 0.1653\n",
      "Time taken for 1 epoch 1093.7170186042786 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(my_dataloader):\n",
    "        inp, targ = inp.to(device), targ.to(device)\n",
    "        batch_loss = train_step(inp, targ, encoder, decoder,\n",
    "                                encoder_optimizer, decoder_optimizer,\n",
    "                                criterion, device, BATCH_SIZE, targ_lang)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss))\n",
    "            \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to figure it out . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'trata de averiguarlo .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ todavia estan en casa ? <end>\n",
      "Predicted translation: are you still at home ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'¿ todavia estan en casa ?', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'esta es mi vida .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s very cold here cold here . <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui .', max_length_targ, max_length_inp, encoder, decoder, inp_lang, targ_lang, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
